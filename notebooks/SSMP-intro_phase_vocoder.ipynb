{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Sound, Speech and Music Processing</center>\n",
    "## <center> Introduction to the Phase Vocoder</center>      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** *The next two cells are only needed to download the sample file. Ignore them if you are going to work with your own audio files.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to run the notebook\n",
    "\n",
    "The notebook can be downloaded and run locally on a computer.\n",
    "\n",
    "Or it can also be run on Google Colab using the following link.\n",
    "<table align=\"center\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/mrocamora/audio-dsp/blob/main/notebooks/SSMP-intro_phase_vocoder.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Introduction\n",
    "\n",
    "This exercise serves as an introduction to the phase vocoder algorithm. An audio signal is analyzed using the STFT and then it is reconstructed by anti-transforming the DFT of each frame and combining them using the Overlap-Add method.\n",
    "\n",
    "The audio signal to be processed is then loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download audio file\n",
    "wget.download('https://github.com/mrocamora/audio-dsp/blob/main/audio/singing_voice.wav?raw=true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the audio file to process (from https://openairlib.net/)\n",
    "filename = 'singing_voice.wav'\n",
    "# filename = 'trumpet.wav'\n",
    "\n",
    "# read audio file\n",
    "fs, x = wavfile.read(filename)\n",
    "\n",
    "# normalize maximum (absolute) amplitude\n",
    "x = x / np.max(abs(x)) * 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time corresponding to the audio signal\n",
    "time_x = np.arange(0, x.size)/fs\n",
    "\n",
    "# plot the audio signal waveform\n",
    "plt.figure(figsize=(12,6))\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "plt.plot(time_x, x)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Part 1\n",
    "\n",
    "In this first part we analyze the effect of the window and the restrictions that must be fulfilled according to the **overlap-add** method.\n",
    "\n",
    "Fill in the code provided below and follow the steps below.\n",
    "\n",
    "1. Properly accumulate the analysis windows according to the **overlap-add** algorithm.\n",
    "2. Calculate the amplitude scaling factor $C$, for the case in which the overlapping of the windows is constant.\n",
    "3. Change the time decimation factor ($R$) and analyze the results. In particular try for $\\frac{1}{4}L$ and $\\frac{3}{4}L$.\n",
    "4. Analyze the result for other smoothing windows (e.g. Hamming, Blackman) using the same decimation factors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of the input signal\n",
    "M = x.size;\n",
    "\n",
    "# length of the analysis window in samples\n",
    "L = 2048\n",
    "\n",
    "# hop size in samples.\n",
    "R = int(L/2)\n",
    "\n",
    "# total number of analysis frames\n",
    "num_frames = int(np.floor((M-L)/R))\n",
    "\n",
    "# analysis window\n",
    "window = signal.windows.get_window('hann', L)\n",
    "\n",
    "# overlap-add (OLA) of the analysis windows\n",
    "olawin = np.zeros((num_frames-1)*R+L)\n",
    "\n",
    "# for each analysis frame\n",
    "for ind in range(num_frames):\n",
    "    \n",
    "    # initial index of current window\n",
    "    n_ini = ind * R\n",
    "    \n",
    "    # overlap-add the window\n",
    "    # olawin[??] =\n",
    "\n",
    "# compute the amplitude scaling factor\n",
    "# C = \n",
    "\n",
    "\n",
    "print(\"C = \", C)\n",
    "print(\"max(olawin) = \", max(olawin))\n",
    "\n",
    "# plot the analysis window\n",
    "plt.figure(figsize=(12,6))\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "plt.plot(window, 'r')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.xlabel('Time (samples)')\n",
    "plt.title('Analysis window')\n",
    "\n",
    "# plot the overlap-add of the analysis windows\n",
    "plt.figure(figsize=(12,6))\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "plt.plot(olawin)\n",
    "plt.xlabel('Time (samples)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Overlap-add of the analysis windows')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "The following code implements the analysis stage of the **phase-vocoder** algorithm, i.e. an STFT.\n",
    "\n",
    "Fill in the code given below by following the steps below.\n",
    "\n",
    "1. Calculate the DFT of each signal frame applying a smoothing window.\n",
    "2. Calculate the frequency value of each bin in radians.\n",
    "3. Calculate the time instant in samples of each frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_STFT(x, L=2048, R=256, win='hann'):\n",
    "    \"\"\" compute the analysis phase of the phase vocoder, i.e. the STFT of the input audio signal\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy array\n",
    "        input audio signal (mono) as a numpy 1D array.\n",
    "    L : int\n",
    "        window length in samples.\n",
    "    R : int\n",
    "        hop size in samples.\n",
    "    win : string\n",
    "          window type as defined in scipy.signal.windows.    \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    X_stft : numpy array\n",
    "             STFT of x as a numpy 2D array.\n",
    "    omega_stft : numpy array\n",
    "                 frequency values in radians.\n",
    "    samps_stft : numpy array\n",
    "                 time sample at the begining of each frame.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # length of the input signal\n",
    "    M = x.size;      \n",
    "    \n",
    "    # number of points to compute the DFT (FFT)\n",
    "    N = L\n",
    "    \n",
    "    # analysis window\n",
    "    window = signal.windows.get_window(win, L)\n",
    "   \n",
    "    # total number of analysis frames\n",
    "    num_frames = int(np.floor((M - L) / R))\n",
    "\n",
    "    # initialize stft\n",
    "    X_stft = np.zeros((N, num_frames), dtype = complex)\n",
    "    \n",
    "    # process each frame\n",
    "    for ind in range(num_frames):\n",
    "\n",
    "        # initial and ending points of the frame\n",
    "        n_ini = int(ind * R)\n",
    "        n_end = n_ini + L\n",
    "\n",
    "        # signal frame\n",
    "        # xr = \n",
    "\n",
    "        # save DFT of the signal frame\n",
    "        # X_stft[:, ind] = \n",
    "        \n",
    "    # frequency values in radians    \n",
    "    # omega_stft = \n",
    "\n",
    "    # time sample at the center of each frame\n",
    "    # samps_stft = \n",
    " \n",
    "    return X_stft, omega_stft, samps_stft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "Once the implementation of the `analysis_STFT` function is complete, follow the steps below.\n",
    "\n",
    "1. Run the `analysis_STFT` function for different values of $L$ and $R$ and analyze the result on the spectrogram.\n",
    "2. What does the $L$ parameter control? What does the $R$ parameter control?\n",
    "3. What relationship must $L$ and $R$ have? Because?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window length in samples\n",
    "L = 2048\n",
    "# hop size in samples\n",
    "R = 256\n",
    "\n",
    "# compute STFT\n",
    "X_stft, omega_stft, samps_stft = analysis_STFT(x, L, R, win='hann')\n",
    "\n",
    "# max frequency index\n",
    "ind_fmax = int(X_stft.shape[0]/2)+1\n",
    "# frequency values (Hz)\n",
    "stft_freqs = omega_stft[:ind_fmax]*fs/(2*np.pi)\n",
    "# time values of the stft\n",
    "stft_time = samps_stft/fs\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "plt.pcolormesh(stft_time, stft_freqs, 20*np.log10(np.abs(X_stft[:ind_fmax, :])), cmap='jet', shading='auto')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4\n",
    "\n",
    "The following code implements the synthesis stage of the STFT.\n",
    "\n",
    "Fill in the code given below and by following the steps below.\n",
    "\n",
    "1. Calculate the reconstruction of each signal frame.\n",
    "2. Accumulate successive frames according to the **overlap-add** method.\n",
    "3. Modify the amplitude of the obtained signal by the window compensation factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesis_STFT(X_stft, L=2048, R=256, win='hann'):\n",
    "    \"\"\" compute the synthesis using the IFFT of each frame combined with overlap-add\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_stft : numpy array\n",
    "             STFT of x as a numpy 2D array.\n",
    "    L : int\n",
    "        window length in samples.\n",
    "    R : int\n",
    "        hop size in samples.\n",
    "    win : string\n",
    "          window type as defined in scipy.signal.windows.    \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    x : numpy array\n",
    "        output audio signal (mono) as a numpy 1D array.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # number of frequency bins\n",
    "    N = X_stft.shape[0];      \n",
    " \n",
    "    # analysis window\n",
    "    window = signal.windows.get_window(win, L)\n",
    "   \n",
    "    # total number of analysis frames\n",
    "    num_frames = X_stft.shape[1]\n",
    "\n",
    "    # initialize otuput signal in the time domain\n",
    "    y = np.zeros(num_frames * R + L)\n",
    "    \n",
    "    # process each frame\n",
    "    for ind in range(num_frames):\n",
    "\n",
    "        # reconstructed signal frame\n",
    "        # yr = \n",
    "\n",
    "        # initial and ending points of the frame\n",
    "        # n_ini = \n",
    "        # n_end = \n",
    "\n",
    "        # overlap-add the signal frame\n",
    "        # y[n_ini:n_end] = \n",
    "        \n",
    "    # compute the amplitude scaling factor\n",
    "    # C = \n",
    "    \n",
    "    # compensate the amplitude scaling factor\n",
    "    y /= C\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5\n",
    "\n",
    "Once the implementation of the `synthesis_STFT` function is complete, follow the steps below.\n",
    "\n",
    "1. Run the `analysis_STFT` function and then the `synthesis_STFT` function using $L=2048$ and $R=256$.\n",
    "2. Evaluate the reconstruction in terms of the waveform. Evaluate the reconstruction aurally.\n",
    "3. Run the `analysis_STFT` function using $L=2048$ and $R=256$. Run the `synthesis_STFT` function using $L=2048$ and $R=512$.\n",
    "4. Before listening to the output, indicate what type of temporary modification you expect to occur. A temporary shortening or lengthening?\n",
    "5. Evaluate the reconstruction in terms of the waveform. Evaluate the reconstruction aurally.\n",
    "6. Repeat part 3 onwards using $L=2048$ and $R=128$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window length in samples\n",
    "L = 2048\n",
    "# hop size in samples\n",
    "R = 256\n",
    "\n",
    "# compute STFT\n",
    "X_stft, omega_stft, samps_stft = analysis_STFT(x, L, R, win='hann')\n",
    "\n",
    "# hop size in samples\n",
    "R = 256\n",
    "\n",
    "# compute the synthesis from the STFT\n",
    "y = synthesis_STFT(X_stft, L, R, win='hann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time corresponding to the audio signal\n",
    "time_y = np.arange(0, y.size)/fs\n",
    "\n",
    "# plot the audio signal waveform\n",
    "plt.figure(figsize=(12,6))\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "plt.plot(time_x, x)\n",
    "plt.ylabel('Amplitude')\n",
    "ax1 = plt.subplot(2, 1, 2)\n",
    "plt.plot(time_y, y)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(y, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

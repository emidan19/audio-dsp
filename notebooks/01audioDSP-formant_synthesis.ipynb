{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> PROCESAMIENTO DIGITAL DE SEÑALES DE AUDIO</center>\n",
    "## <center> Síntesis por cascada de formantes</center>      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción\n",
    "\n",
    "Este ejercicio sirve para estudiar el **modelo del mecanismo de producción de voz**, a través de la síntesis de sonidos vocálicos.\n",
    "\n",
    "La idea consiste en generar un **tren de impulsos** de banda limitada como fuente de excitación glotal, y luego filtrarlo sucesivamente mediante múltiples **resonadores** con frecuencias y anchos de banda correspondientes a las distintas **formantes** de una vocal. Por último, se aplica un filtro pasa-altos como modelo de radiación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cómo correr el notebook\n",
    "Se puede bajar y correr el notebook de forma local en una computadora.\n",
    "\n",
    "O también se puede correr en Google Colab usando el siguiente enlace. \n",
    "\n",
    "<table align=\"center\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/mrocamora/audio-dsp/blob/main/notebooks/audioDSP-formant_synthesis.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resonador\n",
    "\n",
    "A continuación se define una función que implementa un filtro resonador. Estudie sus parámetros de entrada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resonator(x, fs, res_freq, res_bw):\n",
    "    \"\"\"\n",
    "    second order difference equation digital resonator\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x (numpy array)  : input audio waveform\n",
    "    fs (int)         : sampling frequency in Hz\n",
    "    res_freq (float) : resonator frequency in Hz\n",
    "    res_bw (float)   : resonator bandwith in Hz\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y (numpy array) : filtered audio waveform\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    C = -math.exp(-2*math.pi*res_bw/fs)\n",
    "    B = 2*math.exp(-math.pi*res_bw/fs)*math.cos(2*math.pi*res_freq/fs)\n",
    "    A = 1-B-C\n",
    "\n",
    "    T = x.shape[0]\n",
    "    # add two initial null values to x\n",
    "    x = np.insert(x, 0, 0)\n",
    "    x = np.insert(x, 0, 0)\n",
    "    # output signal\n",
    "    y = np.zeros((T+2, 1))\n",
    "\n",
    "    # filtering difference equation\n",
    "    for ind in range(2, T+1):\n",
    "        y[ind] = A*x[ind] + B*y[ind-1] + C*y[ind-2]\n",
    "\n",
    "    y = y[2:]\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Síntesis de formantes\n",
    "\n",
    "La siguiente función implementa la síntesis del sonido de una vocal mediante formantes en cascada.\n",
    "\n",
    "Complete el código que se proporciona a continuación y siguiendo los siguientes pasos. \n",
    "\n",
    "1. Complete las instrucciones necesarias para generar el tren de pulsos (con muestras en 0 y 1).\n",
    "2. Complete las instrucciones necesarias para aplicar los resonadores en cascada para la formante correspondiente.\n",
    "3. Complete las instrucciones necesarias para implementar el filtro pasa-altos del modelo de radiación como una diferencia de primer orden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formant_synthesis(fs=44100, f0=100, dur=1, vowel='a'):\n",
    "    \"\"\"\n",
    "    formant synthesizer\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fs (int)       : sampling frequency in Hz\n",
    "    f0 (float)     : fundamental frequency in Hz\n",
    "    dur (float)    : vowel duration in seconds\n",
    "    vowel (string) : character to set the vowel: 'a' 'e' 'i' 'o' 'u'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y (numpy array) : synthetized audio waveform\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # period in samples\n",
    "    T0 = int(round(fs/f0))\n",
    "    # time instants\n",
    "    t = np.linspace(0, dur, fs*dur)\n",
    "    T = len(t)\n",
    "\n",
    "    # voicing source\n",
    "    vs = np.zeros((T, 1))\n",
    "    # impulse train\n",
    "    # vs[...] = \n",
    "    \n",
    "    # low-pass resonator filter (res_freq = 0 Hz, res_bw = 100 Hz)\n",
    "    vs = resonator(vs, fs, 0, 4*f0)\n",
    "    # amplitude gain in dB\n",
    "    vsGain = 35\n",
    "    # set amplitude gain\n",
    "    vs *= 10**(vsGain/20)\n",
    "\n",
    "    # formants definition\n",
    "    # number of formants for each vowel\n",
    "    num_formants = 4\n",
    "    # formants data\n",
    "    # freq1 bw1 freq2 bw2 freq3 bw3 freq4 bw4\n",
    "    # reference: http://www.sinfomed.org.ar/mains/temas/voctexto.htm\n",
    "    formants_data = {\n",
    "        'a': [830, 105, 1350, 106, 2450, 142, 3655, 197],\n",
    "        'e': [430, 75, 2120, 106, 2628, 140, 3610, 180],\n",
    "        'i': [290, 63, 2295, 103, 2915, 174, 3645, 124],\n",
    "        'o': [510, 83, 860, 105, 2480, 156, 3485, 170],\n",
    "        'u': [335, 80, 720, 112, 2380, 208, 3355, 150]\n",
    "    }\n",
    "    # select formants corresponding to given vowel\n",
    "    try:\n",
    "        formants_values = formants_data[vowel]\n",
    "    except KeyError as e:\n",
    "        print('Error: vowel string not found. Using \\'a\\' as input parameter. KeyError: ' + str(e))\n",
    "        formants_values = formants_data['a']\n",
    "\n",
    "    # cascade filters vocal tract simulation\n",
    "    y = vs\n",
    "    for idx in range(num_formants):\n",
    "        # y = resonator(...)\n",
    "\n",
    "    # radiation characteristic\n",
    "    # y = \n",
    "\n",
    "    # normalization\n",
    "    y = y*0.99/np.max(np.abs(y))\n",
    "\n",
    "    return y, vs, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de la síntesis de formantes\n",
    "\n",
    "El código que se proporciona a continuación sintetiza una vocal con la función implementada anteriormente. Además se grafica la forma de onda de una trama de la excitación, así como la forma de onda y el espectro de una trama de la señal resultante.\n",
    "\n",
    "Ejecute el código y analice lo siguiente. \n",
    "\n",
    "1. Observe que la señal usada como excitación para el banco de filtros resonantes es un tren de pulsos limitado en frecuencia. ¿Es esto coherente con el modelo planteado en clase? ¿Cómo debería cambiar el ancho de banda de la excitación con la intensidad de la señal?\n",
    "2. Analice la forma de onda de la señal resultante. ¿Es una señal periódica? ¿Cuál es su período?\n",
    "3. Analice el espectro de la señal resultante. ¿Logra distinguir con claridad la ubicación de las dos primeras formantes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Síntesis de formantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xv, vs, t = formant_synthesis(vowel='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo de espectro y gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling rate\n",
    "sr = 44100\n",
    "# fundamental frequency\n",
    "f0 = 100\n",
    "# duration\n",
    "dur = 1\n",
    "# window samples\n",
    "N = 2**math.ceil(math.log2(round(4*sr/f0)))\n",
    "# nfft (fft samples)\n",
    "nfft = 2 * N\n",
    "# maximum frequency\n",
    "fmax = 5000\n",
    "# frame indexes\n",
    "tmid = round(dur/2*sr)\n",
    "ind_ini = tmid - int(N/2)\n",
    "ind_end = tmid + int(N/2)\n",
    "# smoothing window\n",
    "window = signal.windows.get_window('hann', N)\n",
    "\n",
    "# signal frame\n",
    "frame = xv[ind_ini:ind_end]\n",
    "\n",
    "# windowed signal frame\n",
    "frame_win = frame[:, 0] * window\n",
    "# spectrum of the signal frame\n",
    "Xv = np.fft.fft(frame_win, nfft)\n",
    "# magnitude spectrum\n",
    "magXv = np.abs(Xv)    \n",
    "\n",
    "# frequency values\n",
    "f = np.fft.fftfreq(nfft) * sr\n",
    "ind_fmx = np.argwhere(f > fmax)[0][0]\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(6, 1, 1)\n",
    "plt.plot(t[ind_ini:ind_end], vs[ind_ini:ind_end], 'k', label='voicing source')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.subplot(6, 1, 2)\n",
    "plt.plot(t[ind_ini:ind_end], xv[ind_ini:ind_end], 'k', label='synthetic signal')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.xlabel('time (s)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(f[:ind_fmx], 20 * np.log10(magXv[:ind_fmx]), 'k', label='spectrum')\n",
    "plt.legend()\n",
    "plt.ylabel('Magnitude (dB)')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Síntesis de vocales\n",
    "\n",
    "El código que se proporciona a continuación sintetiza las cinco vocales y guarda un archivo de audio para cada una. Además se grafica la forma de onda y el espectro de cada señal de audio.\n",
    "\n",
    "Ejecute el código y siga los siguientes pasos. \n",
    "\n",
    "1. Evalúe auditivamente el resultado de la síntesis. ¿Logra diferenciar el sonido de cada vocal?\n",
    "2. Compare la forma de onda de cada vocal. ¿Logra distinguir las diferencias dadas por las diferentes formantes?\n",
    "3. Compare el espectro de cada vocal. ¿Logra distinguir con claridad las diferencias en la ubicación de las dos primeras formantes?\n",
    "4. Considere el mapa de formantes presentado en clase. ¿La ubicación de las formantes sigue esa caracterización? \n",
    "5. Nuevamente evalúe auditivamente el resultado de la síntesis. ¿Qué limitantes identifica en la síntesis que hacen que el sonido sea poco realista?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling rate\n",
    "sr = 44100\n",
    "# formants\n",
    "vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "# list of numpy arrays (audio waveforms)\n",
    "s = []\n",
    "\n",
    "# test formant synthesis\n",
    "for v in vowels:\n",
    "    xv, _, _ = formant_synthesis(vowel=v)\n",
    "    # save for ploting\n",
    "    s.append(xv)\n",
    "    # write audio file (44100, 16 bits)\n",
    "    wxv = xv * 32767\n",
    "    wavfile.write('./' + v +'.wav', sr, wxv.astype(np.int16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluación auditiva de la síntesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr, data = wavfile.read('a.wav')\n",
    "ipd.Audio(data, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr, data = wavfile.read('e.wav')\n",
    "ipd.Audio(data, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr, data = wavfile.read('i.wav')\n",
    "ipd.Audio(data, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr, data = wavfile.read('o.wav')\n",
    "ipd.Audio(data, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr, data = wavfile.read('u.wav')\n",
    "ipd.Audio(data, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graficar forma de onda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of samples to plot\n",
    "ns = 4096\n",
    "# number of vowels\n",
    "num_vowels = len(vowels)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "for index, v in enumerate(vowels):\n",
    "    xv = s[index]\n",
    "    plt.subplot(num_vowels, 1, index+1)\n",
    "    plt.plot(xv[:ns], 'k', label=v)\n",
    "    plt.legend()\n",
    "    plt.xlim([0, ns])\n",
    "    plt.ylabel('Amplitude')\n",
    "plt.xlabel('Time (samples)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcular y graficar espectro de una trama de señal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window samples\n",
    "f0 = 100\n",
    "N = 2**math.ceil(math.log2(round(4*sr/f0)))\n",
    "# nfft (fft samples)\n",
    "nfft = 2 * N\n",
    "# maximum frequency\n",
    "fmax = 5000\n",
    "# duration\n",
    "dur = 1\n",
    "# frame indexes\n",
    "tmid = round(dur/2*sr)\n",
    "ind_ini = tmid - int(N/2)\n",
    "ind_end = tmid + int(N/2)\n",
    "# smoothing window\n",
    "window = signal.windows.get_window('hann', N)\n",
    "\n",
    "# list of numpy arrays (spectrums)\n",
    "Xs = []\n",
    "\n",
    "for index, v in enumerate(vowels):\n",
    "    # waveform\n",
    "    xv = s[index]\n",
    "    # signal frame\n",
    "    frame = xv[ind_ini:ind_end]\n",
    "    # windowed signal frame\n",
    "    frame_win = frame[:, 0] * window\n",
    "    # spectrum of the signal frame\n",
    "    Xv = np.fft.fft(frame_win, nfft)\n",
    "    # save spectrum\n",
    "    Xs.append(Xv)\n",
    "\n",
    "# frequency values\n",
    "f = np.fft.fftfreq(nfft) * sr\n",
    "ind_fmx = np.argwhere(f > fmax)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,24))\n",
    "for index, v in enumerate(vowels):\n",
    "    # spectrum\n",
    "    Xv = Xs[index]\n",
    "    # magnitude spectrum\n",
    "    magX = np.abs(Xv)    \n",
    "    plt.subplot(num_vowels, 1, index+1)\n",
    "    plt.plot(f[:ind_fmx], 20 * np.log10(magX[:ind_fmx]), 'k', label=v)\n",
    "    plt.legend()\n",
    "    plt.ylabel('Magnitude (dB)')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

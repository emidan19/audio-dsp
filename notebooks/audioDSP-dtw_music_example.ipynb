{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> PROCESAMIENTO DIGITAL DE SEÑALES DE AUDIO</center>\n",
    "## <center> Dynamic Time Warping (DTW)</center>\n",
    "### <center> Music alignment example</center>\n",
    "\n",
    "Code based on: [librosa_gallery](https://librosa.github.io/librosa/auto_examples/plot_music_sync.html#sphx-glr-auto-examples-plot-music-sync-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy, scipy.spatial \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA:** *Las siguientes dos celdas solo son necesarias para descargar el archivo de ejemplo. Ignórelas si va a trabajar con sus propios archivos de audio.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción\n",
    "\n",
    "En este ejemplo se estudia el alineamiento mediante Dynamic Time Warping (DTW) de dos señales de música usando como representación el cromagrama. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cómo correr el notebook\n",
    "Se puede bajar y correr el notebook de forma local en una computadora.\n",
    "\n",
    "O también se puede correr en Google Colab usando el siguiente enlace. \n",
    "\n",
    "<table align=\"center\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/mrocamora/audio-dsp/blob/main/notebooks/audioDSP-dtw_music_example.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Señales de audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download audio files\n",
    "wget.download('https://github.com/mrocamora/audio-dsp/blob/main/audio/sir_duke_slow.mp3?raw=true')\n",
    "wget.download('https://github.com/mrocamora/audio-dsp/blob/main/audio/sir_duke_fast.mp3?raw=true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1, fs = librosa.load('sir_duke_slow.mp3')\n",
    "plt.figure(figsize=(16, 4))\n",
    "librosa.display.waveplot(x_1, sr=fs)\n",
    "plt.title('Slower Version $X_1$')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x_1, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2, fs = librosa.load('sir_duke_fast.mp3')\n",
    "plt.figure(figsize=(16, 4))\n",
    "librosa.display.waveplot(x_2, sr=fs)\n",
    "plt.title('Faster Version $X_2$')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x_2, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listen to the two recordings toghether to verify they are not synchronized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = np.min([len(x_1), len(x_2)])\n",
    "audio_1_s = x_1[:ml]\n",
    "audio_2_s = x_2[:ml]\n",
    "audio_stereo = np.hstack((audio_2_s.reshape(-1, 1), audio_1_s.reshape(-1, 1)))\n",
    "\n",
    "print('Not synchronized versions', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(audio_stereo.T, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chrome features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_size = 256\n",
    "\n",
    "x_1_chroma = librosa.feature.chroma_stft(y=x_1, sr=fs, tuning=0, norm=2,\n",
    "                                         hop_length=hop_size)\n",
    "x_2_chroma = librosa.feature.chroma_stft(y=x_2, sr=fs, tuning=0, norm=2,\n",
    "                                         hop_length=hop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Chroma Representation of $X_1$')\n",
    "librosa.display.specshow(x_1_chroma, x_axis='time',\n",
    "                         y_axis='chroma', cmap='coolwarm', hop_length=hop_size)\n",
    "plt.colorbar()\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Chroma Representation of $X_2$')\n",
    "librosa.display.specshow(x_2_chroma, x_axis='time',\n",
    "                         y_axis='chroma', cmap='coolwarm', hop_length=hop_size)\n",
    "plt.colorbar()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## DTW functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtw_table(x, y, distance=None):\n",
    "    if distance is None:\n",
    "        distance = scipy.spatial.distance.euclidean\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    table = np.zeros((nx+1, ny+1))\n",
    "    \n",
    "    # Compute left column separately, i.e. j=0.\n",
    "    table[1:, 0] = np.inf\n",
    "        \n",
    "    # Compute top row separately, i.e. i=0.\n",
    "    table[0, 1:] = np.inf\n",
    "        \n",
    "    # Fill in the rest.\n",
    "    for i in range(1, nx+1):\n",
    "        for j in range(1, ny+1):\n",
    "            d = distance(x[i-1], y[j-1])\n",
    "            table[i, j] = d + min(table[i-1, j], table[i, j-1], table[i-1, j-1])\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtw(x, y, table):\n",
    "    i = len(x)\n",
    "    j = len(y)\n",
    "    path = [(i, j)]\n",
    "    while i > 0 or j > 0:\n",
    "        minval = np.inf\n",
    "        if table[i-1][j-1] < minval:\n",
    "            minval = table[i-1, j-1]\n",
    "            step = (i-1, j-1)\n",
    "        if table[i-1, j] < minval:\n",
    "            minval = table[i-1, j]\n",
    "            step = (i-1, j)\n",
    "        if table[i][j-1] < minval:\n",
    "            minval = table[i, j-1]\n",
    "            step = (i, j-1)\n",
    "        path.insert(0, step)\n",
    "        i, j = step\n",
    "    return np.array(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Align chroma sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = dtw_table(x_1_chroma.T, x_2_chroma.T, distance=scipy.spatial.distance.cityblock)\n",
    "\n",
    "path = dtw(x_1_chroma.T, x_2_chroma.T, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the best path on top of local similarity matrix\n",
    "plt.figure(figsize=(9, 8))\n",
    "\n",
    "# bottom right plot\n",
    "ax1 = plt.axes([0.2, 0, 0.8, 0.20])\n",
    "ax1.imshow(x_1_chroma, origin='lower', aspect='auto', cmap='coolwarm')\n",
    "ax1.set_xlabel('Chroma Representation of $X_1$')\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "\n",
    "# top left plot\n",
    "ax2 = plt.axes([0, 0.2, 0.20, 0.8])\n",
    "ax2.imshow(x_2_chroma.T[:,::-1], origin='lower', aspect='auto', cmap='coolwarm')\n",
    "ax2.set_ylabel('Chroma Representation of $X_2$')\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "\n",
    "# top right plot\n",
    "ax3 = plt.axes([0.2, 0.2, 0.8, 0.8])\n",
    "ax3.imshow(D.T, aspect='auto', origin='lower', interpolation='nearest', cmap='gray')\n",
    "ax3.set_xticks([])\n",
    "ax3.set_yticks([])\n",
    "\n",
    "# path\n",
    "ax3.plot(path[:,0], path[:,1], 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative visualization of the alignment\n",
    "\n",
    "We can also visualize the wariping path directly on the chroma representation of the signals.\n",
    "Black lines connect corresponding time positions in the chroma representation of the signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 5))\n",
    "\n",
    "# top plot\n",
    "ax1 = plt.axes([0, 0.60, 1, 0.40])\n",
    "ax1.imshow(x_1_chroma, origin='lower', aspect='auto', cmap='coolwarm')\n",
    "ax1.set_ylabel('Signal 1')\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "#ax1.set_ylim(20)\n",
    "ax1.set_xlim(0, x_1_chroma.shape[1])\n",
    "\n",
    "# bottom plot\n",
    "ax2 = plt.axes([0, 0, 1, 0.40])\n",
    "ax2.imshow(x_2_chroma, origin='lower', aspect='auto', cmap='coolwarm')\n",
    "ax2.set_ylabel('Signal 2')\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "#ax2.set_ylim(20)\n",
    "ax2.set_xlim(0, x_2_chroma.shape[1])\n",
    "\n",
    "# middle plot\n",
    "line_color = 'k'\n",
    "step = 30\n",
    "n1 = float(x_1_chroma.shape[1])\n",
    "n2 = float(x_2_chroma.shape[1])\n",
    "ax3 = plt.axes([0, 0.40, 1, 0.20])\n",
    "for t in path[::step]:\n",
    "    ax3.plot((t[0]/n1, t[1]/n2), (1, -1), color=line_color)\n",
    "    ax3.set_xlim(0, 1)\n",
    "    ax3.set_ylim(-1, 1)\n",
    "    \n",
    "# reference marker    \n",
    "ref_mark = 300\n",
    "marker_color = 'r'\n",
    "t = path[ref_mark]\n",
    "ax3.plot((t[0]/n1, t[1]/n2), (1, -1), color=marker_color)\n",
    "    \n",
    "# path markers on top and bottom plot\n",
    "y1_min, y1_max = ax1.get_ylim()\n",
    "y2_min, y2_max = ax2.get_ylim()\n",
    "ax1.vlines([t[0] for t in path[::step]], y1_min, y1_max, color=line_color)\n",
    "ax2.vlines([t[1] for t in path[::step]], y2_min, y2_max, color=line_color)\n",
    "t = path[ref_mark]\n",
    "ax1.vlines(t[0], y1_min, y1_max, color=marker_color)\n",
    "ax2.vlines(t[1], y2_min, y2_max, color=marker_color)\n",
    "ax3.set_xticks([])\n",
    "ax3.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listen to the alignment\n",
    "\n",
    "Listen to the both recordings at the same alignment marker:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of the alignment\n",
    "print(path.shape)\n",
    "\n",
    "# convert frame to samples\n",
    "i1, i2 = librosa.frames_to_samples(path[ref_mark], hop_length=hop_size)\n",
    "print(i1, i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x_1[i1:], rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x_2[i2:], rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "ax1 = plt.subplot(211)\n",
    "#librosa.display.waveplot(x_1, sr=fs)\n",
    "plt.plot(x_1)\n",
    "ax1.vlines(i1, -0.5, 0.5, color=marker_color)\n",
    "plt.title('Slower Version $X_1$')\n",
    "plt.tight_layout()\n",
    "ax2 = plt.subplot(212)\n",
    "#librosa.display.waveplot(x_2, sr=fs)\n",
    "plt.plot(x_2)\n",
    "ax2.vlines(i2, -0.5, 0.5, color=marker_color)\n",
    "plt.title('Slower Version $X_1$')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listen to aligned audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download audio files\n",
    "wget.download('https://github.com/mrocamora/audio-dsp/blob/main/audio/stereo_matched_sir_duke.wav?raw=true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stereo aligned audio\n",
    "d_align, sr_align = librosa.load('stereo_matched_sir_duke.wav', sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(d_align, rate=sr_align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

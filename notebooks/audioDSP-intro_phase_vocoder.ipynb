{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> PROCESAMIENTO DIGITAL DE SEÑALES DE AUDIO</center>\n",
    "## <center> Introducción al algoritmo de Phase Vocoder</center>      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA:** *Las siguientes dos celdas solo son necesarias para descargar el archivo de ejemplo. Ignórelas si va a trabajar con sus propios archivos de audio.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cómo correr el notebook\n",
    "Se puede bajar y correr el notebook de forma local en una computadora.\n",
    "\n",
    "O también se puede correr en Google Colab usando el siguiente enlace. \n",
    "\n",
    "<table align=\"center\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/mrocamora/audio-dsp/blob/main/notebooks/audioDSP-intro_phase_vocoder.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción\n",
    "\n",
    "Este ejercicio sirve de introducción al algoritmo de phase vocoder. Se analiza una señal de audio usando la STFT y luego se la reconstruye antitransformando la DFT de cada trama y combinándolas mediante el método de Overlap-Add.\n",
    "\n",
    "A continuación se carga la señal de audio que será procesada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download audio file\n",
    "wget.download('https://github.com/mrocamora/audio-dsp/blob/main/audio/singing_voice.wav?raw=true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the audio file to process (from https://openairlib.net/)\n",
    "filename = 'singing_voice.wav'\n",
    "# filename = './audio/trumpet.wav'\n",
    "\n",
    "# read audio file\n",
    "fs, x = wavfile.read(filename)\n",
    "\n",
    "# normalize maximum (absolute) amplitude\n",
    "x = x / np.max(abs(x)) * 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time corresponding to the audio signal\n",
    "time_x = np.arange(0, x.size)/fs\n",
    "\n",
    "# plot the audio signal waveform\n",
    "plt.figure(figsize=(12,6))\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "plt.plot(time_x, x)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1\n",
    "\n",
    "En esta primera parte se analiza el efecto del enventanado y las restricciones que debe cumplir según el método de **overlap-add**. \n",
    "\n",
    "Complete el código que se proporciona a continuación y siga los siguientes pasos. \n",
    "\n",
    "1. Acumular adecuadamente las ventanas de análisis de acuerdo al algoritmo de **overlap-add**.\n",
    "2. Calcular el factor de escalado de amplitud $C$, para el caso en que el solapamiento de las ventanas es constante.\n",
    "3. Cambiar el factor de decimación temporal ($R$) y analice los resultados. En particular pruebe para $\\frac{1}{4} L$ y $\\frac{3}{4} L$.\n",
    "4. Analice el resultado para otras ventanas suavizantes (e.g. Hamming, Blackman) usando los mismos factores de decimación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of the input signal\n",
    "M = x.size;\n",
    "\n",
    "# length of the analysis window in samples\n",
    "L = 2048\n",
    "\n",
    "# hop size in samples.\n",
    "R = int(L/2)\n",
    "\n",
    "# total number of analysis frames\n",
    "num_frames = int(np.floor((M-L)/R))\n",
    "\n",
    "# analysis window\n",
    "window = signal.windows.get_window('hann', L)\n",
    "\n",
    "# overlap-add (OLA) of the analysis windows\n",
    "olawin = np.zeros((num_frames-1)*R+L)\n",
    "\n",
    "# for each analysis frame\n",
    "for ind in range(num_frames):\n",
    "    \n",
    "    # initial index of current window\n",
    "    n_ini = ind * R\n",
    "    \n",
    "    # overlap-add the window\n",
    "    # olawin[??] =\n",
    "\n",
    "# compute the amplitude scaling factor\n",
    "# C = \n",
    "\n",
    "\n",
    "print(\"C = \", C)\n",
    "print(\"max(olawin) = \", max(olawin))\n",
    "\n",
    "# plot the analysis window\n",
    "plt.figure(figsize=(12,6))\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "plt.plot(window, 'r')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.xlabel('Time (samples)')\n",
    "plt.title('Analysis window')\n",
    "\n",
    "# plot the overlap-add of the analysis windows\n",
    "plt.figure(figsize=(12,6))\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "plt.plot(olawin)\n",
    "plt.xlabel('Time (samples)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Overlap-add of the analysis windows')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2\n",
    "\n",
    "El siguiente código implementa la etapa de análisis del algoritmo de **phase-vocoder**, es decir una STFT. \n",
    "\n",
    "Complete el código que se proporciona a continuación y siguiendo los siguientes pasos. \n",
    "\n",
    "1. Calcular la DFT de cada trama de señal aplicando una ventana suavizante.\n",
    "2. Calcular el valor de frequencia de cada bin en radianes.\n",
    "3. Calcular el instante temporal en muestras de cada trama.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_STFT(x, L=2048, R=256, win='hann'):\n",
    "    \"\"\" compute the analysis phase of the phase vocoder, i.e. the STFT of the input audio signal\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy array\n",
    "        input audio signal (mono) as a numpy 1D array.\n",
    "    L : int\n",
    "        window length in samples.\n",
    "    R : int\n",
    "        hop size in samples.\n",
    "    win : string\n",
    "          window type as defined in scipy.signal.windows.    \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    X_stft : numpy array\n",
    "             STFT of x as a numpy 2D array.\n",
    "    omega_stft : numpy array\n",
    "                 frequency values in radians.\n",
    "    samps_stft : numpy array\n",
    "                 time sample at the begining of each frame.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # length of the input signal\n",
    "    M = x.size;      \n",
    "    \n",
    "    # number of points to compute the DFT (FFT)\n",
    "    N = L\n",
    "    \n",
    "    # analysis window\n",
    "    window = signal.windows.get_window(win, L)\n",
    "   \n",
    "    # total number of analysis frames\n",
    "    num_frames = int(np.floor((M - L) / R))\n",
    "\n",
    "    # initialize stft\n",
    "    X_stft = np.zeros((N, num_frames), dtype = complex)\n",
    "    \n",
    "    # process each frame\n",
    "    for ind in range(num_frames):\n",
    "\n",
    "        # initial and ending points of the frame\n",
    "        n_ini = int(ind * R)\n",
    "        n_end = n_ini + L\n",
    "\n",
    "        # signal frame\n",
    "        # xr = \n",
    "\n",
    "        # save DFT of the signal frame\n",
    "        # X_stft[:, ind] = \n",
    "        \n",
    "    # frequency values in radians    \n",
    "    # omega_stft = \n",
    "\n",
    "    # time sample at the center of each frame\n",
    "    # samps_stft = \n",
    " \n",
    "    return X_stft, omega_stft, samps_stft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3\n",
    "\n",
    "Una vez completada la implementación de la función `analysis_STFT` siga los siguientes pasos.\n",
    "\n",
    "1. Ejecute la función `analysis_STFT` para distintos valores de $L$ y $R$ y analice el resultado en el espectragrama.\n",
    "2. ¿Qué controla el parámetro $L$? ¿Qué controla el parámetro $R$? \n",
    "3. ¿Qué relación deben cumplir $L$ y $R$? ¿Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window length in samples\n",
    "L = 2048\n",
    "# hop size in samples\n",
    "R = 256\n",
    "\n",
    "# compute STFT\n",
    "X_stft, omega_stft, samps_stft = analysis_STFT(x, L, R, win='hann')\n",
    "\n",
    "# max frequency index\n",
    "ind_fmax = int(X_stft.shape[0]/2)+1\n",
    "# frequency values (Hz)\n",
    "stft_freqs = omega_stft[:ind_fmax]*fs/(2*np.pi)\n",
    "# time values of the stft\n",
    "stft_time = samps_stft/fs\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "plt.pcolormesh(stft_time, stft_freqs, 20*np.log10(np.abs(X_stft[:ind_fmax, :])), cmap='jet')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 4\n",
    "\n",
    "El siguiente código implementa la etapa de síntesis a partir de la STFT. \n",
    "\n",
    "Complete el código que se proporciona a continuación y siguiendo los siguientes pasos. \n",
    "\n",
    "1. Calcule la reconstrucción de cada trama de señal.\n",
    "2. Acumule tramas sucesivas según el método de **overlap-adds**.\n",
    "3. Modifique la amplitud de la señal obtenida por el factor de compensación del enventanado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesis_STFT(X_stft, L=2048, R=256, win='hann'):\n",
    "    \"\"\" compute the synthesis using the IFFT of each frame combined with overlap-add\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_stft : numpy array\n",
    "             STFT of x as a numpy 2D array.\n",
    "    L : int\n",
    "        window length in samples.\n",
    "    R : int\n",
    "        hop size in samples.\n",
    "    win : string\n",
    "          window type as defined in scipy.signal.windows.    \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    x : numpy array\n",
    "        output audio signal (mono) as a numpy 1D array.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # number of frequency bins\n",
    "    N = X_stft.shape[0];      \n",
    " \n",
    "    # analysis window\n",
    "    window = signal.windows.get_window(win, L)\n",
    "   \n",
    "    # total number of analysis frames\n",
    "    num_frames = X_stft.shape[1]\n",
    "\n",
    "    # initialize otuput signal in the time domain\n",
    "    y = np.zeros(num_frames * R + L)\n",
    "    \n",
    "    # process each frame\n",
    "    for ind in range(num_frames):\n",
    "\n",
    "        # reconstructed signal frame\n",
    "        # yr = \n",
    "\n",
    "        # initial and ending points of the frame\n",
    "        # n_ini = \n",
    "        # n_end = \n",
    "\n",
    "        # overlap-add the signal frame\n",
    "        # y[n_ini:n_end] = \n",
    "        \n",
    "    # compute the amplitude scaling factor\n",
    "    # C = \n",
    "    \n",
    "    # compensate the amplitude scaling factor\n",
    "    y /= C\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 5\n",
    "\n",
    "Una vez completada la implementación de la función `synthesis_STFT` siga los siguientes pasos.\n",
    "\n",
    "1. Ejecute la función `analysis_STFT` y luego la función `synthesis_STFT` usando $L=2048$ y $R=256$. \n",
    "2. Evalúe la reconstrucción en términos de la forma de onda. Evalúe la reconstrucción auditivamente.\n",
    "3. Ejecute la función `analysis_STFT` usando $L=2048$ y $R=256$. Ejecute la función `synthesis_STFT` usando $L=2048$ y $R=512$. \n",
    "4. Antes de escuchar el resultado indique qué tipo de modificación temporal espera que se produzca. ¿Una acortamiento o alargamiento temporal?\n",
    "5. Evalúe la reconstrucción en términos de la forma de onda. Evalúe la reconstrucción auditivamente.\n",
    "6. Repita la parte 3 en adelante usando $L=2048$ y $R=128$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window length in samples\n",
    "L = 2048\n",
    "# hop size in samples\n",
    "R = 256\n",
    "\n",
    "# compute STFT\n",
    "X_stft, omega_stft, samps_stft = analysis_STFT(x, L, R, win='hann')\n",
    "\n",
    "# hop size in samples\n",
    "R = 256\n",
    "\n",
    "# compute the synthesis from the STFT\n",
    "y = synthesis_STFT(X_stft, L, R, win='hann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time corresponding to the audio signal\n",
    "time_y = np.arange(0, y.size)/fs\n",
    "\n",
    "# plot the audio signal waveform\n",
    "plt.figure(figsize=(12,6))\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "plt.plot(time_x, x)\n",
    "plt.ylabel('Amplitude')\n",
    "ax1 = plt.subplot(2, 1, 2)\n",
    "plt.plot(time_y, y)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(y, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
